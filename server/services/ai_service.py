from langchain_community.llms import Ollama

class AIService:
    def __init__(self):
        self.llm = None
        self.is_active = False
        
        # × ×™×¡×™×•×Ÿ ×˜×¢×™× ×” "×‘×˜×•×—" - ×œ× ×™×¤×™×œ ××ª ×”×©×¨×ª ×× ×”×¡×¤×¨×™×™×” ×œ× ××•×ª×§× ×ª
        try:
            # ×× ×¡×™× ×œ×™×™×‘× ×¨×§ ×× ×§×™×™×
            from langchain_ollama import OllamaLLM
            self.llm = OllamaLLM(model="llama3")
            self.is_active = True
            print("âœ… AI Service initialized (Ready to connect to Docker/Local Ollama)")
            
        except ImportError:
            print("âš ï¸ langchain-ollama not installed. AI Service running in MOCK mode.")
        except Exception as e:
            print(f"âš ï¸ AI Service warning: {e}. Running in MOCK mode.")

    def analyze_stock(self, symbol: str, price: float) -> str:
        # ×× ××™×Ÿ ×œ× ×• ××•×“×œ ×××™×ª×™, × ×—×–×™×¨ ×ª×©×•×‘×ª ×“××”
        if not self.is_active or not self.llm:
            return (f"[MOCK Analysis] The AI service is currently optimized via Docker. "
                    f"Mock insight: {symbol} at ${price} shows stable trends. "
                    f"Consider market volatility before investing.")

        # × ×™×¡×™×•×Ÿ ×¤× ×™×™×” ×œ××•×“×œ ×”×××™×ª×™ (×× ×”×•× ××•×ª×§×Ÿ)
        try:
            prompt = f"Analyze the stock {symbol} at {price} USD. Is it risky? Answer in 2 short sentences."
            return self.llm.invoke(prompt)
        except Exception as e:
            print(f"âŒ Connection to Ollama failed: {e}")
            return "AI Service is offline. Please check your Docker container."
    
    def generate_investment_plan(self, prompt: str) -> str:
        """
        ×™×¦×™×¨×ª ×ª×›× ×™×ª ×”×©×§×¢×” ××•×ª×××ª ××™×©×™×ª ×‘×××¦×¢×•×ª AI
        """
        # ×× ××™×Ÿ ××•×“×œ ×××™×ª×™, × ×—×–×™×¨ ×ª×•×›× ×™×ª ×“××”
        if not self.is_active or not self.llm:
            return """
ğŸ“Š INVESTMENT PLAN - Based on Your Profile

ğŸ¯ Top 5 Stock Recommendations:
1. NVDA (40%) - Nvidia - Strong tech growth, high dividend potential
2. AAPL (25%) - Apple - Stable blue-chip, defensive position
3. JNJ (20%) - Johnson & Johnson - Dividend stock, low risk
4. MSFT (10%) - Microsoft - Cloud growth exposure
5. Cash Reserve (5%) - Liquidity buffer for short-term opportunities

ğŸ“ˆ Expected Performance:
- Annual Return Projection: 6-8% (Conservative approach)
- Risk Level: Low-Medium
- Volatility Index: Moderate

â° Implementation Timeline:
Week 1: Allocate 50% of capital
Week 2-3: Allocate remaining 50%
Monitor quarterly, rebalance annually

âœ… Diversification Score: 85% - Well-balanced across sectors
ğŸ›¡ï¸ Risk Assessment: CONSERVATIVE - Suitable for your profile
            """
        
        # × ×™×¡×™×•×Ÿ ×¤× ×™×™×” ×œ××•×“×œ ×”×××™×ª×™ (×× Ollama ×¨×¥)
        try:
            print(f"ğŸ¤– AI Service: Generating investment plan with Llama3...")
            response = self.llm.invoke(prompt)
            return str(response).strip()
        except Exception as e:
            print(f"âŒ AI Error: {e}")
            print(f"âš ï¸ Falling back to mock mode...")
            return """
ğŸ“Š INVESTMENT PLAN - MOCK MODE (AI Unavailable)

ğŸ¯ Top 5 Stock Recommendations:
1. NVDA (40%) - Nvidia - Strong tech growth
2. AAPL (25%) - Apple - Stable blue-chip
3. JNJ (20%) - Johnson & Johnson - Dividend stock
4. MSFT (10%) - Microsoft - Cloud growth
5. Cash Reserve (5%) - Liquidity buffer

ğŸ“ˆ Expected Performance:
- Annual Return: 6-8%
- Risk Level: Low-Medium
- Diversification: 85%

âš ï¸ Note: This is a mock analysis. Ensure Ollama is running for real AI recommendations.
            """